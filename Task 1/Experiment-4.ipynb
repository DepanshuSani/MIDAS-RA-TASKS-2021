{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "import scipy.io.wavfile as wav\n",
    "import scipy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Install dependencies and unzip dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting py7zr\n",
      "  Downloading py7zr-0.15.1-py3-none-any.whl (66 kB)\n",
      "\u001b[K     |████████████████████████████████| 66 kB 2.5 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting multivolumefile<0.3.0,>=0.2.0\n",
      "  Downloading multivolumefile-0.2.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: texttable in /opt/conda/lib/python3.7/site-packages (from py7zr) (1.6.3)\n",
      "Collecting ppmd-cffi<0.5.0,>=0.4.1\n",
      "  Downloading ppmd_cffi-0.4.1-cp37-cp37m-manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[K     |████████████████████████████████| 124 kB 7.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from py7zr) (3.4.0)\n",
      "Collecting bcj-cffi<0.6.0,>=0.5.1\n",
      "  Downloading bcj_cffi-0.5.1-cp37-cp37m-manylinux2014_x86_64.whl (36 kB)\n",
      "Collecting pyzstd<0.15.0,>=0.14.4\n",
      "  Downloading pyzstd-0.14.4-cp37-cp37m-manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |███████████████████████████████▉| 2.2 MB 7.4 MB/s eta 0:00:01     |████████████████████████████████| 2.2 MB 7.4 MB/s \n",
      "\u001b[?25hCollecting pycryptodome\n",
      "  Downloading pycryptodome-3.10.1-cp35-abi3-manylinux2010_x86_64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from bcj-cffi<0.6.0,>=0.5.1->py7zr) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.14.0->bcj-cffi<0.6.0,>=0.5.1->py7zr) (2.20)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->py7zr) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->py7zr) (3.7.4.3)\n",
      "Installing collected packages: pyzstd, pycryptodome, ppmd-cffi, multivolumefile, bcj-cffi, py7zr\n",
      "Successfully installed bcj-cffi-0.5.1 multivolumefile-0.2.2 ppmd-cffi-0.4.1 py7zr-0.15.1 pycryptodome-3.10.1 pyzstd-0.14.4\n"
     ]
    }
   ],
   "source": [
    "!pip install py7zr\n",
    "!py7zr x '../input/tensorflow-speech-recognition-challenge/train.7z'\n",
    "!py7zr x '../input/tensorflow-speech-recognition-challenge/test.7z'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = './train/audio'\n",
    "labels = os.listdir(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset of all labels except silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "five, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/librosa/core/pitch.py:153: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn(\"Trying to estimate tuning from empty frequency set.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog, _background_noise_, marvin, happy, seven, go, three, four, bird, bed, cat, tree, yes, zero, on, eight, right, stop, wow, sheila, off, "
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for label in labels:\n",
    "    print(label, end=\", \")\n",
    "    path = os.path.join(TRAIN_DIR, label)\n",
    "    filenames = os.listdir(path)\n",
    "    for filename in filenames:\n",
    "        if \".wav\" not in filename or label == \"_background_noise_\":\n",
    "            continue\n",
    "        audio, sr = librosa.load(os.path.join(path, filename))\n",
    "        audio = audio[:sr:10]\n",
    "        audio = np.pad(audio, (0, 2205-len(audio)), mode=\"constant\", constant_values=0)\n",
    "        audio = np.reshape(audio, (315,7)) # Reshaping samples to create dataset of shape (TIMESTEP, FEATURES)\n",
    "        X.append(audio)\n",
    "        Y.append(labels.index(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset creation of silence label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"_background_noise_\"\n",
    "path = os.path.join(TRAIN_DIR, label)\n",
    "filenames = os.listdir(path)\n",
    "for filename in filenames:\n",
    "    if \".wav\" not in filename:\n",
    "        continue\n",
    "    audio, sr = librosa.load(os.path.join(path, filename))\n",
    "    for i in range(0, sr, sr):\n",
    "        a = audio[i:i+sr:10]\n",
    "        a = np.pad(a, (0, 2205-len(a)), mode=\"constant\", constant_values=0)\n",
    "        a = np.reshape(a, (315,7))\n",
    "        X.append(a)\n",
    "        Y.append(labels.index(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(X, dropout=0.4):\n",
    "    _input = tf.keras.layers.Input(X)\n",
    "    x = tf.keras.layers.Conv1D(64, 3, padding=\"same\")(_input)\n",
    "    x = tf.keras.layers.Activation(tf.nn.leaky_relu)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)    \n",
    "    x = tf.keras.layers.MaxPool1D()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv1D(128, 3, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.Activation(tf.nn.leaky_relu)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)    \n",
    "    x = tf.keras.layers.MaxPool1D()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv1D(256, 3, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.Activation(tf.nn.leaky_relu)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPool1D()(x)\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(128)(x)\n",
    "    x = tf.keras.layers.Activation(tf.nn.leaky_relu)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(64)(x)\n",
    "    x = tf.keras.layers.Activation(tf.nn.leaky_relu)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(len(labels))(x)\n",
    "    x = tf.keras.layers.Activation(tf.nn.softmax)(x)\n",
    "    return tf.keras.Model(_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(x_train[0].shape)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "checkpoint_filepath = \"weights_mfcc_Conv2D/\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of the output shape and parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 100, 16)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 100, 64)           3136      \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 100, 64)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 100, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 50, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 50, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 50, 128)           24704     \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 50, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 25, 256)           98560     \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 25, 256)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 25, 256)           1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 12, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               393344    \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 31)                2015      \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 31)                0         \n",
      "=================================================================\n",
      "Total params: 532,575\n",
      "Trainable params: 531,295\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.2174 - accuracy: 0.6392 - val_loss: 1.6416 - val_accuracy: 0.5505\n",
      "Epoch 2/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2175 - accuracy: 0.6381 - val_loss: 1.7376 - val_accuracy: 0.5365\n",
      "Epoch 3/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.2117 - accuracy: 0.6398 - val_loss: 1.5391 - val_accuracy: 0.5534\n",
      "Epoch 4/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2176 - accuracy: 0.6380 - val_loss: 2.8696 - val_accuracy: 0.3154\n",
      "Epoch 5/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2102 - accuracy: 0.6410 - val_loss: 1.6887 - val_accuracy: 0.5354\n",
      "Epoch 6/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2079 - accuracy: 0.6397 - val_loss: 1.7844 - val_accuracy: 0.5073\n",
      "Epoch 7/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.2132 - accuracy: 0.6416 - val_loss: 2.0316 - val_accuracy: 0.4805\n",
      "Epoch 8/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2215 - accuracy: 0.6375 - val_loss: 1.7076 - val_accuracy: 0.5152\n",
      "Epoch 9/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2111 - accuracy: 0.6379 - val_loss: 1.6332 - val_accuracy: 0.5440\n",
      "Epoch 10/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2126 - accuracy: 0.6389 - val_loss: 2.7721 - val_accuracy: 0.3582\n",
      "Epoch 11/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.2011 - accuracy: 0.6387 - val_loss: 1.9510 - val_accuracy: 0.4576\n",
      "Epoch 12/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.2085 - accuracy: 0.6415 - val_loss: 2.0035 - val_accuracy: 0.4625\n",
      "Epoch 13/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2066 - accuracy: 0.6403 - val_loss: 2.4147 - val_accuracy: 0.4089\n",
      "Epoch 14/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2046 - accuracy: 0.6432 - val_loss: 1.5381 - val_accuracy: 0.5767\n",
      "Epoch 15/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.2063 - accuracy: 0.6381 - val_loss: 1.5299 - val_accuracy: 0.5634\n",
      "Epoch 16/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2195 - accuracy: 0.6372 - val_loss: 1.3172 - val_accuracy: 0.6202\n",
      "Epoch 17/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2097 - accuracy: 0.6399 - val_loss: 1.4798 - val_accuracy: 0.5757\n",
      "Epoch 18/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2200 - accuracy: 0.6354 - val_loss: 1.3302 - val_accuracy: 0.6199\n",
      "Epoch 19/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2100 - accuracy: 0.6375 - val_loss: 1.6804 - val_accuracy: 0.5414\n",
      "Epoch 20/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.2159 - accuracy: 0.6386 - val_loss: 1.4232 - val_accuracy: 0.5948\n",
      "Epoch 21/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2064 - accuracy: 0.6389 - val_loss: 1.8585 - val_accuracy: 0.5052\n",
      "Epoch 22/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2086 - accuracy: 0.6421 - val_loss: 1.3991 - val_accuracy: 0.5983\n",
      "Epoch 23/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2050 - accuracy: 0.6401 - val_loss: 4.7746 - val_accuracy: 0.2047\n",
      "Epoch 24/500\n",
      "287/287 [==============================] - 3s 11ms/step - loss: 1.2093 - accuracy: 0.6398 - val_loss: 1.5991 - val_accuracy: 0.5602\n",
      "Epoch 25/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1992 - accuracy: 0.6444 - val_loss: 1.6348 - val_accuracy: 0.5431\n",
      "Epoch 26/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2029 - accuracy: 0.6395 - val_loss: 1.5664 - val_accuracy: 0.5612\n",
      "Epoch 27/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2186 - accuracy: 0.6400 - val_loss: 1.6932 - val_accuracy: 0.5298\n",
      "Epoch 28/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.2170 - accuracy: 0.6356 - val_loss: 1.3351 - val_accuracy: 0.6140\n",
      "Epoch 29/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1888 - accuracy: 0.6407 - val_loss: 1.3582 - val_accuracy: 0.6088\n",
      "Epoch 30/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2076 - accuracy: 0.6401 - val_loss: 1.7486 - val_accuracy: 0.5304\n",
      "Epoch 31/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2053 - accuracy: 0.6436 - val_loss: 1.3098 - val_accuracy: 0.6224\n",
      "Epoch 32/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1963 - accuracy: 0.6426 - val_loss: 1.7452 - val_accuracy: 0.5208\n",
      "Epoch 33/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2136 - accuracy: 0.6398 - val_loss: 1.5939 - val_accuracy: 0.5483\n",
      "Epoch 34/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2021 - accuracy: 0.6410 - val_loss: 1.8468 - val_accuracy: 0.4859\n",
      "Epoch 35/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2106 - accuracy: 0.6398 - val_loss: 1.9863 - val_accuracy: 0.4615\n",
      "Epoch 36/500\n",
      "287/287 [==============================] - 3s 11ms/step - loss: 1.2009 - accuracy: 0.6399 - val_loss: 1.7188 - val_accuracy: 0.5233\n",
      "Epoch 37/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2056 - accuracy: 0.6413 - val_loss: 1.8109 - val_accuracy: 0.4956\n",
      "Epoch 38/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1959 - accuracy: 0.6450 - val_loss: 1.7203 - val_accuracy: 0.5160\n",
      "Epoch 39/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1972 - accuracy: 0.6436 - val_loss: 1.5383 - val_accuracy: 0.5726\n",
      "Epoch 40/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.2100 - accuracy: 0.6407 - val_loss: 1.4125 - val_accuracy: 0.6049\n",
      "Epoch 41/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2090 - accuracy: 0.6418 - val_loss: 1.3516 - val_accuracy: 0.6052\n",
      "Epoch 42/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2085 - accuracy: 0.6399 - val_loss: 1.4094 - val_accuracy: 0.5954\n",
      "Epoch 43/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2137 - accuracy: 0.6379 - val_loss: 1.8386 - val_accuracy: 0.4870\n",
      "Epoch 44/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2003 - accuracy: 0.6405 - val_loss: 1.5316 - val_accuracy: 0.5559\n",
      "Epoch 45/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1986 - accuracy: 0.6418 - val_loss: 2.0797 - val_accuracy: 0.4657\n",
      "Epoch 46/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2013 - accuracy: 0.6404 - val_loss: 1.3418 - val_accuracy: 0.6108\n",
      "Epoch 47/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2033 - accuracy: 0.6386 - val_loss: 1.8392 - val_accuracy: 0.4833\n",
      "Epoch 48/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.2060 - accuracy: 0.6412 - val_loss: 1.7703 - val_accuracy: 0.5037\n",
      "Epoch 49/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.2119 - accuracy: 0.6400 - val_loss: 1.5253 - val_accuracy: 0.5721\n",
      "Epoch 50/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1952 - accuracy: 0.6443 - val_loss: 1.5747 - val_accuracy: 0.5498\n",
      "Epoch 51/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2077 - accuracy: 0.6405 - val_loss: 2.0577 - val_accuracy: 0.4519\n",
      "Epoch 52/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1961 - accuracy: 0.6442 - val_loss: 1.5422 - val_accuracy: 0.5574\n",
      "Epoch 53/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2030 - accuracy: 0.6438 - val_loss: 1.4166 - val_accuracy: 0.5927\n",
      "Epoch 54/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1966 - accuracy: 0.6436 - val_loss: 1.5130 - val_accuracy: 0.5765\n",
      "Epoch 55/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2044 - accuracy: 0.6389 - val_loss: 1.5354 - val_accuracy: 0.5764\n",
      "Epoch 56/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1923 - accuracy: 0.6479 - val_loss: 1.9466 - val_accuracy: 0.4641\n",
      "Epoch 57/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.2013 - accuracy: 0.6448 - val_loss: 3.1737 - val_accuracy: 0.3016\n",
      "Epoch 58/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2029 - accuracy: 0.6444 - val_loss: 1.8678 - val_accuracy: 0.4913\n",
      "Epoch 59/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2064 - accuracy: 0.6415 - val_loss: 1.8178 - val_accuracy: 0.5073\n",
      "Epoch 60/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.2081 - accuracy: 0.6404 - val_loss: 1.2959 - val_accuracy: 0.6304\n",
      "Epoch 61/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.2061 - accuracy: 0.6431 - val_loss: 1.4469 - val_accuracy: 0.5856\n",
      "Epoch 62/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2053 - accuracy: 0.6415 - val_loss: 1.5243 - val_accuracy: 0.5658\n",
      "Epoch 63/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2015 - accuracy: 0.6424 - val_loss: 1.3738 - val_accuracy: 0.6128\n",
      "Epoch 64/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2054 - accuracy: 0.6404 - val_loss: 1.7122 - val_accuracy: 0.5383\n",
      "Epoch 65/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1968 - accuracy: 0.6436 - val_loss: 1.7414 - val_accuracy: 0.5276\n",
      "Epoch 66/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2012 - accuracy: 0.6408 - val_loss: 2.2369 - val_accuracy: 0.4064\n",
      "Epoch 67/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1937 - accuracy: 0.6455 - val_loss: 1.6012 - val_accuracy: 0.5493\n",
      "Epoch 68/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1998 - accuracy: 0.6433 - val_loss: 1.6177 - val_accuracy: 0.5499\n",
      "Epoch 69/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1976 - accuracy: 0.6399 - val_loss: 2.4776 - val_accuracy: 0.3932\n",
      "Epoch 70/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1989 - accuracy: 0.6418 - val_loss: 1.4773 - val_accuracy: 0.5883\n",
      "Epoch 71/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2039 - accuracy: 0.6385 - val_loss: 1.6129 - val_accuracy: 0.5452\n",
      "Epoch 72/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1996 - accuracy: 0.6432 - val_loss: 1.4616 - val_accuracy: 0.5834\n",
      "Epoch 73/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.2009 - accuracy: 0.6414 - val_loss: 1.5355 - val_accuracy: 0.5791\n",
      "Epoch 74/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.2000 - accuracy: 0.6419 - val_loss: 1.3626 - val_accuracy: 0.6082\n",
      "Epoch 75/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2020 - accuracy: 0.6402 - val_loss: 1.6464 - val_accuracy: 0.5406\n",
      "Epoch 76/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2010 - accuracy: 0.6443 - val_loss: 1.3252 - val_accuracy: 0.6233\n",
      "Epoch 77/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2010 - accuracy: 0.6442 - val_loss: 1.4199 - val_accuracy: 0.5945\n",
      "Epoch 78/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1973 - accuracy: 0.6453 - val_loss: 1.3568 - val_accuracy: 0.6109\n",
      "Epoch 79/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1956 - accuracy: 0.6450 - val_loss: 1.4041 - val_accuracy: 0.6067\n",
      "Epoch 80/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1958 - accuracy: 0.6449 - val_loss: 1.4987 - val_accuracy: 0.5806\n",
      "Epoch 81/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1914 - accuracy: 0.6458 - val_loss: 1.6794 - val_accuracy: 0.5289\n",
      "Epoch 82/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1920 - accuracy: 0.6445 - val_loss: 1.4007 - val_accuracy: 0.6001\n",
      "Epoch 83/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2012 - accuracy: 0.6405 - val_loss: 1.3310 - val_accuracy: 0.6138\n",
      "Epoch 84/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1821 - accuracy: 0.6466 - val_loss: 1.3884 - val_accuracy: 0.6062\n",
      "Epoch 85/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1952 - accuracy: 0.6428 - val_loss: 1.5694 - val_accuracy: 0.5597\n",
      "Epoch 86/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.2015 - accuracy: 0.6441 - val_loss: 1.3586 - val_accuracy: 0.6099\n",
      "Epoch 87/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1966 - accuracy: 0.6433 - val_loss: 1.4174 - val_accuracy: 0.5986\n",
      "Epoch 88/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1994 - accuracy: 0.6430 - val_loss: 1.5542 - val_accuracy: 0.5567\n",
      "Epoch 89/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1896 - accuracy: 0.6441 - val_loss: 1.5608 - val_accuracy: 0.5692\n",
      "Epoch 90/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.2048 - accuracy: 0.6419 - val_loss: 1.3732 - val_accuracy: 0.6059\n",
      "Epoch 91/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1973 - accuracy: 0.6413 - val_loss: 1.5999 - val_accuracy: 0.5447\n",
      "Epoch 92/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1898 - accuracy: 0.6459 - val_loss: 1.6172 - val_accuracy: 0.5518\n",
      "Epoch 93/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1910 - accuracy: 0.6457 - val_loss: 2.0951 - val_accuracy: 0.4353\n",
      "Epoch 94/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1939 - accuracy: 0.6453 - val_loss: 1.5183 - val_accuracy: 0.5853\n",
      "Epoch 95/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1969 - accuracy: 0.6432 - val_loss: 1.8140 - val_accuracy: 0.4959\n",
      "Epoch 96/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1824 - accuracy: 0.6485 - val_loss: 1.3567 - val_accuracy: 0.6176\n",
      "Epoch 97/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1952 - accuracy: 0.6419 - val_loss: 1.2900 - val_accuracy: 0.6249\n",
      "Epoch 98/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1871 - accuracy: 0.6441 - val_loss: 1.8887 - val_accuracy: 0.4995\n",
      "Epoch 99/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1895 - accuracy: 0.6488 - val_loss: 1.5431 - val_accuracy: 0.5666\n",
      "Epoch 100/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1872 - accuracy: 0.6457 - val_loss: 1.3582 - val_accuracy: 0.6039\n",
      "Epoch 101/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1897 - accuracy: 0.6455 - val_loss: 1.6082 - val_accuracy: 0.5615\n",
      "Epoch 102/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1892 - accuracy: 0.6421 - val_loss: 1.8278 - val_accuracy: 0.4957\n",
      "Epoch 103/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1987 - accuracy: 0.6442 - val_loss: 1.5931 - val_accuracy: 0.5682\n",
      "Epoch 104/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1961 - accuracy: 0.6441 - val_loss: 1.3659 - val_accuracy: 0.6167\n",
      "Epoch 105/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1932 - accuracy: 0.6437 - val_loss: 1.4076 - val_accuracy: 0.6085\n",
      "Epoch 106/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1935 - accuracy: 0.6449 - val_loss: 1.5171 - val_accuracy: 0.5784\n",
      "Epoch 107/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1851 - accuracy: 0.6463 - val_loss: 1.9278 - val_accuracy: 0.4659\n",
      "Epoch 108/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1899 - accuracy: 0.6446 - val_loss: 2.6455 - val_accuracy: 0.3524\n",
      "Epoch 109/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1947 - accuracy: 0.6458 - val_loss: 1.3110 - val_accuracy: 0.6261\n",
      "Epoch 110/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1850 - accuracy: 0.6457 - val_loss: 1.8553 - val_accuracy: 0.4896\n",
      "Epoch 111/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1877 - accuracy: 0.6437 - val_loss: 1.4115 - val_accuracy: 0.5974\n",
      "Epoch 112/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1913 - accuracy: 0.6425 - val_loss: 1.6372 - val_accuracy: 0.5422\n",
      "Epoch 113/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1924 - accuracy: 0.6427 - val_loss: 1.6007 - val_accuracy: 0.5448\n",
      "Epoch 114/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1936 - accuracy: 0.6454 - val_loss: 1.5553 - val_accuracy: 0.5696\n",
      "Epoch 115/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1900 - accuracy: 0.6443 - val_loss: 1.3904 - val_accuracy: 0.6036\n",
      "Epoch 116/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1879 - accuracy: 0.6463 - val_loss: 4.4165 - val_accuracy: 0.1718\n",
      "Epoch 117/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1908 - accuracy: 0.6428 - val_loss: 1.7906 - val_accuracy: 0.5143\n",
      "Epoch 118/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1968 - accuracy: 0.6446 - val_loss: 1.8282 - val_accuracy: 0.4922\n",
      "Epoch 119/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1975 - accuracy: 0.6427 - val_loss: 1.3552 - val_accuracy: 0.6113\n",
      "Epoch 120/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1809 - accuracy: 0.6475 - val_loss: 1.4304 - val_accuracy: 0.5983\n",
      "Epoch 121/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1794 - accuracy: 0.6491 - val_loss: 1.4177 - val_accuracy: 0.5941\n",
      "Epoch 122/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1940 - accuracy: 0.6445 - val_loss: 1.3585 - val_accuracy: 0.6123\n",
      "Epoch 123/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1814 - accuracy: 0.6480 - val_loss: 1.6324 - val_accuracy: 0.5452\n",
      "Epoch 124/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1846 - accuracy: 0.6458 - val_loss: 1.5312 - val_accuracy: 0.5792\n",
      "Epoch 125/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1884 - accuracy: 0.6457 - val_loss: 1.8426 - val_accuracy: 0.4961\n",
      "Epoch 126/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1783 - accuracy: 0.6451 - val_loss: 1.8953 - val_accuracy: 0.4855\n",
      "Epoch 127/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1868 - accuracy: 0.6468 - val_loss: 1.6014 - val_accuracy: 0.5567\n",
      "Epoch 128/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1958 - accuracy: 0.6446 - val_loss: 1.3596 - val_accuracy: 0.6172\n",
      "Epoch 129/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1921 - accuracy: 0.6438 - val_loss: 2.5147 - val_accuracy: 0.3721\n",
      "Epoch 130/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1873 - accuracy: 0.6467 - val_loss: 1.5776 - val_accuracy: 0.5507\n",
      "Epoch 131/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1814 - accuracy: 0.6457 - val_loss: 1.7693 - val_accuracy: 0.5090\n",
      "Epoch 132/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1946 - accuracy: 0.6440 - val_loss: 1.6945 - val_accuracy: 0.5326\n",
      "Epoch 133/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1937 - accuracy: 0.6447 - val_loss: 1.8620 - val_accuracy: 0.4826\n",
      "Epoch 134/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1781 - accuracy: 0.6494 - val_loss: 1.5304 - val_accuracy: 0.5733\n",
      "Epoch 135/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1917 - accuracy: 0.6426 - val_loss: 1.4725 - val_accuracy: 0.5927\n",
      "Epoch 136/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1818 - accuracy: 0.6482 - val_loss: 1.3386 - val_accuracy: 0.6154\n",
      "Epoch 137/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1836 - accuracy: 0.6480 - val_loss: 1.4896 - val_accuracy: 0.5689\n",
      "Epoch 138/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1800 - accuracy: 0.6454 - val_loss: 1.2978 - val_accuracy: 0.6288\n",
      "Epoch 139/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1903 - accuracy: 0.6461 - val_loss: 1.4330 - val_accuracy: 0.6009\n",
      "Epoch 140/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1889 - accuracy: 0.6490 - val_loss: 1.8354 - val_accuracy: 0.5013\n",
      "Epoch 141/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1833 - accuracy: 0.6507 - val_loss: 1.7560 - val_accuracy: 0.5193\n",
      "Epoch 142/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1954 - accuracy: 0.6424 - val_loss: 1.4252 - val_accuracy: 0.6047\n",
      "Epoch 143/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1807 - accuracy: 0.6490 - val_loss: 1.3546 - val_accuracy: 0.6178\n",
      "Epoch 144/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1885 - accuracy: 0.6459 - val_loss: 1.3681 - val_accuracy: 0.6070\n",
      "Epoch 145/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1889 - accuracy: 0.6472 - val_loss: 1.4607 - val_accuracy: 0.5902\n",
      "Epoch 146/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1779 - accuracy: 0.6488 - val_loss: 1.2836 - val_accuracy: 0.6334\n",
      "Epoch 147/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1881 - accuracy: 0.6461 - val_loss: 1.6782 - val_accuracy: 0.5351\n",
      "Epoch 148/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.2000 - accuracy: 0.6442 - val_loss: 1.3720 - val_accuracy: 0.6144\n",
      "Epoch 149/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1874 - accuracy: 0.6464 - val_loss: 1.7979 - val_accuracy: 0.4824\n",
      "Epoch 150/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1852 - accuracy: 0.6434 - val_loss: 1.3588 - val_accuracy: 0.6070\n",
      "Epoch 151/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1985 - accuracy: 0.6428 - val_loss: 1.3312 - val_accuracy: 0.6182\n",
      "Epoch 152/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1769 - accuracy: 0.6486 - val_loss: 1.6673 - val_accuracy: 0.5266\n",
      "Epoch 153/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1888 - accuracy: 0.6445 - val_loss: 1.3380 - val_accuracy: 0.6154\n",
      "Epoch 154/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1911 - accuracy: 0.6485 - val_loss: 1.5391 - val_accuracy: 0.5599\n",
      "Epoch 155/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1746 - accuracy: 0.6531 - val_loss: 1.3525 - val_accuracy: 0.6230\n",
      "Epoch 156/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1814 - accuracy: 0.6493 - val_loss: 1.3665 - val_accuracy: 0.6077\n",
      "Epoch 157/500\n",
      "287/287 [==============================] - 3s 11ms/step - loss: 1.1845 - accuracy: 0.6461 - val_loss: 1.4795 - val_accuracy: 0.5753\n",
      "Epoch 158/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1782 - accuracy: 0.6487 - val_loss: 1.8007 - val_accuracy: 0.4897\n",
      "Epoch 159/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1773 - accuracy: 0.6493 - val_loss: 1.3394 - val_accuracy: 0.6171\n",
      "Epoch 160/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1893 - accuracy: 0.6442 - val_loss: 1.3662 - val_accuracy: 0.6043\n",
      "Epoch 161/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1828 - accuracy: 0.6486 - val_loss: 1.8437 - val_accuracy: 0.4929\n",
      "Epoch 162/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1825 - accuracy: 0.6480 - val_loss: 1.6360 - val_accuracy: 0.5366\n",
      "Epoch 163/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1757 - accuracy: 0.6529 - val_loss: 1.4983 - val_accuracy: 0.5751\n",
      "Epoch 164/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1768 - accuracy: 0.6479 - val_loss: 1.4530 - val_accuracy: 0.5923\n",
      "Epoch 165/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1858 - accuracy: 0.6437 - val_loss: 1.5149 - val_accuracy: 0.5709\n",
      "Epoch 166/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1835 - accuracy: 0.6456 - val_loss: 1.3910 - val_accuracy: 0.6018\n",
      "Epoch 167/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1721 - accuracy: 0.6515 - val_loss: 1.5509 - val_accuracy: 0.5645\n",
      "Epoch 168/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1893 - accuracy: 0.6478 - val_loss: 1.3623 - val_accuracy: 0.6178\n",
      "Epoch 169/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1872 - accuracy: 0.6446 - val_loss: 1.3939 - val_accuracy: 0.6030\n",
      "Epoch 170/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1820 - accuracy: 0.6488 - val_loss: 1.4403 - val_accuracy: 0.5927\n",
      "Epoch 171/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1845 - accuracy: 0.6473 - val_loss: 1.4624 - val_accuracy: 0.5877\n",
      "Epoch 172/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1789 - accuracy: 0.6476 - val_loss: 1.3695 - val_accuracy: 0.6131\n",
      "Epoch 173/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1787 - accuracy: 0.6491 - val_loss: 1.6567 - val_accuracy: 0.5497\n",
      "Epoch 174/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1807 - accuracy: 0.6509 - val_loss: 1.4650 - val_accuracy: 0.5834\n",
      "Epoch 175/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1852 - accuracy: 0.6454 - val_loss: 1.6677 - val_accuracy: 0.5422\n",
      "Epoch 176/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1903 - accuracy: 0.6442 - val_loss: 1.3120 - val_accuracy: 0.6245\n",
      "Epoch 177/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1874 - accuracy: 0.6448 - val_loss: 2.1576 - val_accuracy: 0.4349\n",
      "Epoch 178/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1819 - accuracy: 0.6470 - val_loss: 1.4396 - val_accuracy: 0.5941\n",
      "Epoch 179/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1888 - accuracy: 0.6468 - val_loss: 2.1014 - val_accuracy: 0.4521\n",
      "Epoch 180/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1845 - accuracy: 0.6481 - val_loss: 1.6116 - val_accuracy: 0.5467\n",
      "Epoch 181/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1807 - accuracy: 0.6465 - val_loss: 1.5756 - val_accuracy: 0.5496\n",
      "Epoch 182/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1785 - accuracy: 0.6506 - val_loss: 1.5871 - val_accuracy: 0.5634\n",
      "Epoch 183/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1839 - accuracy: 0.6453 - val_loss: 1.3540 - val_accuracy: 0.6226\n",
      "Epoch 184/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1701 - accuracy: 0.6494 - val_loss: 1.7380 - val_accuracy: 0.5231\n",
      "Epoch 185/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1669 - accuracy: 0.6531 - val_loss: 1.2990 - val_accuracy: 0.6264\n",
      "Epoch 186/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1818 - accuracy: 0.6486 - val_loss: 1.4710 - val_accuracy: 0.5882\n",
      "Epoch 187/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1822 - accuracy: 0.6466 - val_loss: 1.8708 - val_accuracy: 0.5039\n",
      "Epoch 188/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1850 - accuracy: 0.6464 - val_loss: 1.3767 - val_accuracy: 0.6111\n",
      "Epoch 189/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1776 - accuracy: 0.6491 - val_loss: 1.3590 - val_accuracy: 0.6206\n",
      "Epoch 190/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1878 - accuracy: 0.6454 - val_loss: 1.5852 - val_accuracy: 0.5719\n",
      "Epoch 191/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1751 - accuracy: 0.6508 - val_loss: 2.7417 - val_accuracy: 0.3364\n",
      "Epoch 192/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1757 - accuracy: 0.6512 - val_loss: 1.3171 - val_accuracy: 0.6211\n",
      "Epoch 193/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1823 - accuracy: 0.6478 - val_loss: 1.5061 - val_accuracy: 0.5733\n",
      "Epoch 194/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1870 - accuracy: 0.6472 - val_loss: 1.8030 - val_accuracy: 0.5035\n",
      "Epoch 195/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1817 - accuracy: 0.6491 - val_loss: 1.5042 - val_accuracy: 0.5696\n",
      "Epoch 196/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1713 - accuracy: 0.6533 - val_loss: 1.4580 - val_accuracy: 0.5917\n",
      "Epoch 197/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1775 - accuracy: 0.6513 - val_loss: 2.3729 - val_accuracy: 0.4017\n",
      "Epoch 198/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1833 - accuracy: 0.6470 - val_loss: 1.4249 - val_accuracy: 0.6036\n",
      "Epoch 199/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1743 - accuracy: 0.6499 - val_loss: 1.9643 - val_accuracy: 0.4526\n",
      "Epoch 200/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1769 - accuracy: 0.6513 - val_loss: 1.9773 - val_accuracy: 0.4644\n",
      "Epoch 201/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1761 - accuracy: 0.6520 - val_loss: 1.4214 - val_accuracy: 0.5959\n",
      "Epoch 202/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1824 - accuracy: 0.6462 - val_loss: 1.7665 - val_accuracy: 0.5127\n",
      "Epoch 203/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1845 - accuracy: 0.6489 - val_loss: 2.1156 - val_accuracy: 0.4302\n",
      "Epoch 204/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1761 - accuracy: 0.6502 - val_loss: 1.3129 - val_accuracy: 0.6344\n",
      "Epoch 205/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1838 - accuracy: 0.6448 - val_loss: 1.4026 - val_accuracy: 0.6011\n",
      "Epoch 206/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1702 - accuracy: 0.6537 - val_loss: 1.3521 - val_accuracy: 0.6201\n",
      "Epoch 207/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1734 - accuracy: 0.6494 - val_loss: 1.3936 - val_accuracy: 0.6025\n",
      "Epoch 208/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1753 - accuracy: 0.6481 - val_loss: 1.5745 - val_accuracy: 0.5714\n",
      "Epoch 209/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1795 - accuracy: 0.6481 - val_loss: 1.5092 - val_accuracy: 0.5738\n",
      "Epoch 210/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1804 - accuracy: 0.6495 - val_loss: 1.5076 - val_accuracy: 0.5745\n",
      "Epoch 211/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1719 - accuracy: 0.6506 - val_loss: 1.3152 - val_accuracy: 0.6275\n",
      "Epoch 212/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1569 - accuracy: 0.6536 - val_loss: 1.4108 - val_accuracy: 0.5970\n",
      "Epoch 213/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1809 - accuracy: 0.6479 - val_loss: 1.3763 - val_accuracy: 0.6184\n",
      "Epoch 214/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1877 - accuracy: 0.6455 - val_loss: 1.7202 - val_accuracy: 0.5371\n",
      "Epoch 215/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1786 - accuracy: 0.6469 - val_loss: 1.3387 - val_accuracy: 0.6119\n",
      "Epoch 216/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1809 - accuracy: 0.6466 - val_loss: 1.8345 - val_accuracy: 0.5013\n",
      "Epoch 217/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1790 - accuracy: 0.6493 - val_loss: 1.4046 - val_accuracy: 0.5993\n",
      "Epoch 218/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1774 - accuracy: 0.6500 - val_loss: 1.3395 - val_accuracy: 0.6117\n",
      "Epoch 219/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1790 - accuracy: 0.6496 - val_loss: 1.5917 - val_accuracy: 0.5534\n",
      "Epoch 220/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1680 - accuracy: 0.6514 - val_loss: 1.3350 - val_accuracy: 0.6251\n",
      "Epoch 221/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1783 - accuracy: 0.6448 - val_loss: 1.5911 - val_accuracy: 0.5495\n",
      "Epoch 222/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1739 - accuracy: 0.6503 - val_loss: 1.5575 - val_accuracy: 0.5540\n",
      "Epoch 223/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1751 - accuracy: 0.6469 - val_loss: 1.3770 - val_accuracy: 0.6122\n",
      "Epoch 224/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1839 - accuracy: 0.6482 - val_loss: 1.3275 - val_accuracy: 0.6232\n",
      "Epoch 225/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1798 - accuracy: 0.6480 - val_loss: 1.7951 - val_accuracy: 0.4921\n",
      "Epoch 226/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1729 - accuracy: 0.6483 - val_loss: 1.3553 - val_accuracy: 0.6116\n",
      "Epoch 227/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1771 - accuracy: 0.6509 - val_loss: 1.3540 - val_accuracy: 0.6151\n",
      "Epoch 228/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1762 - accuracy: 0.6500 - val_loss: 1.5296 - val_accuracy: 0.5687\n",
      "Epoch 229/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1716 - accuracy: 0.6482 - val_loss: 1.5389 - val_accuracy: 0.5724\n",
      "Epoch 230/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1733 - accuracy: 0.6490 - val_loss: 1.4031 - val_accuracy: 0.6019\n",
      "Epoch 231/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1733 - accuracy: 0.6492 - val_loss: 1.3080 - val_accuracy: 0.6245\n",
      "Epoch 232/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1826 - accuracy: 0.6470 - val_loss: 1.9791 - val_accuracy: 0.4601\n",
      "Epoch 233/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1725 - accuracy: 0.6471 - val_loss: 1.3232 - val_accuracy: 0.6213\n",
      "Epoch 234/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1682 - accuracy: 0.6510 - val_loss: 1.5210 - val_accuracy: 0.5788\n",
      "Epoch 235/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1765 - accuracy: 0.6498 - val_loss: 1.3451 - val_accuracy: 0.6173\n",
      "Epoch 236/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1724 - accuracy: 0.6530 - val_loss: 2.1677 - val_accuracy: 0.4543\n",
      "Epoch 237/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1671 - accuracy: 0.6510 - val_loss: 1.3550 - val_accuracy: 0.6181\n",
      "Epoch 238/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1764 - accuracy: 0.6476 - val_loss: 1.7417 - val_accuracy: 0.5176\n",
      "Epoch 239/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1683 - accuracy: 0.6537 - val_loss: 1.5786 - val_accuracy: 0.5586\n",
      "Epoch 240/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1761 - accuracy: 0.6481 - val_loss: 1.5489 - val_accuracy: 0.5652\n",
      "Epoch 241/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1717 - accuracy: 0.6498 - val_loss: 1.4036 - val_accuracy: 0.6075\n",
      "Epoch 242/500\n",
      "287/287 [==============================] - 3s 10ms/step - loss: 1.1657 - accuracy: 0.6516 - val_loss: 1.3727 - val_accuracy: 0.6097\n",
      "Epoch 243/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1745 - accuracy: 0.6508 - val_loss: 1.5860 - val_accuracy: 0.5537\n",
      "Epoch 244/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1644 - accuracy: 0.6529 - val_loss: 1.3031 - val_accuracy: 0.6323\n",
      "Epoch 245/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1720 - accuracy: 0.6490 - val_loss: 1.3630 - val_accuracy: 0.6129\n",
      "Epoch 246/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1670 - accuracy: 0.6497 - val_loss: 1.7037 - val_accuracy: 0.5308\n",
      "Epoch 247/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1719 - accuracy: 0.6526 - val_loss: 1.3995 - val_accuracy: 0.6057\n",
      "Epoch 248/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1725 - accuracy: 0.6494 - val_loss: 1.7578 - val_accuracy: 0.5014\n",
      "Epoch 249/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1657 - accuracy: 0.6532 - val_loss: 1.7001 - val_accuracy: 0.5397\n",
      "Epoch 250/500\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 1.1734 - accuracy: 0.6495 - val_loss: 1.3215 - val_accuracy: 0.6236\n",
      "Epoch 251/500\n",
      "188/287 [==================>...........] - ETA: 0s - loss: 1.1732 - accuracy: 0.6480"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-4ff6acad2759>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "H = model.fit(x_train, y_train, batch_size=128, epochs=500, validation_split=0.25, shuffle=True, callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of the train history (X-axis: <i>EPOCHS</i>, Y-axis: <i>ACCURACY</i>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe3166f74d0>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(H.history[\"accuracy\"])\n",
    "plt.plot(H.history[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best weights and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509/509 [==============================] - 1s 3ms/step - loss: 1.2941 - accuracy: 0.6433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2941157817840576, 0.6433265805244446]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"weights_mfcc_Conv2D/\")\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
